"""
Ù…Ø§Ú˜ÙˆÙ„ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÙˆØ±Ø³ Ø§Ø² API
"""
import requests
import pandas as pd
import time
from typing import Optional, List
import logging

from config import API_BASE_URL, INDUSTRY_CODES, INDUSTRY_NAMES, CSV_COLUMNS

# ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BourseDataFetcher:
    """Ú©Ù„Ø§Ø³ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÙˆØ±Ø³ Ø§Ø² API"""
    
    def __init__(self):
        self.base_url = API_BASE_URL
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.industry_codes = INDUSTRY_CODES
        self.industry_names = INDUSTRY_NAMES
        self.columns = CSV_COLUMNS
    
    def fetch_industry_data(self, industry_code: str) -> Optional[pd.DataFrame]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ ÛŒÚ© ØµÙ†Ø¹Øª Ø®Ø§Øµ
        
        Args:
            industry_code: Ú©Ø¯ ØµÙ†Ø¹Øª (Ù…Ø«Ù„Ø§Ù‹ '43')
            
        Returns:
            DataFrame Ø­Ø§ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ù‡Ø§Ù… Ø¢Ù† ØµÙ†Ø¹Øª ÛŒØ§ None Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
        """
        try:
            # ØªÙˆÙ„ÛŒØ¯ timestamp Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² cache
            timestamp = int(time.time() * 1000)
            url = f"{self.base_url}{industry_code}?_={timestamp}"
            
            logger.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ ØµÙ†Ø¹Øª {industry_code} ({self.industry_names.get(industry_code, 'Ù†Ø§Ù…Ø´Ø®Øµ')})")
            
            # Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            # ØªØ¨Ø¯ÛŒÙ„ JSON Ø¨Ù‡ DataFrame
            data = response.json()
            
            if not data:
                logger.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØµÙ†Ø¹Øª {industry_code} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯")
                return None
            
            df = pd.DataFrame(data, columns=self.columns)
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØµÙ†Ø¹Øª
            df['industry_code'] = industry_code
            df['industry_name'] = self.industry_names.get(industry_code, 'Ù†Ø§Ù…Ø´Ø®Øµ')
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±
            df = self._convert_dtypes(df)
            
            logger.info(f"âœ… {len(df)} Ø³Ù‡Ù… Ø§Ø² ØµÙ†Ø¹Øª {self.industry_names.get(industry_code)} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
            
            return df
            
        except requests.exceptions.Timeout:
            logger.error(f"âŒ Timeout Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ ØµÙ†Ø¹Øª {industry_code}")
            return None
            
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ ØµÙ†Ø¹Øª {industry_code}: {e}")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ ØµÙ†Ø¹Øª {industry_code}: {e}")
            return None
    
    def fetch_all_industries(self, industry_codes: Optional[List[str]] = None, batch_size: int = 5) -> pd.DataFrame:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ù‡Ù…Ù‡ ØµÙ†Ø§ÛŒØ¹ Ø¨Ù‡ ØµÙˆØ±Øª batch
        
        Args:
            industry_codes: Ù„ÛŒØ³Øª Ú©Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¹Øª (Ø§Ú¯Ø± None Ø¨Ø§Ø´Ø¯ØŒ Ù‡Ù…Ù‡ ØµÙ†Ø§ÛŒØ¹ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒØ´ÙˆØ¯)
            batch_size: ØªØ¹Ø¯Ø§Ø¯ ØµÙ†Ø§ÛŒØ¹ Ø¯Ø± Ù‡Ø± batch (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 5)
            
        Returns:
            DataFrame Ø­Ø§ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ…Ø§Ù… ØµÙ†Ø§ÛŒØ¹
        """
        if industry_codes is None:
            industry_codes = self.industry_codes
        
        all_data = []
        failed_industries = []
        
        total_industries = len(industry_codes)
        logger.info(f"Ø´Ø±ÙˆØ¹ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² {total_industries} ØµÙ†Ø¹Øª (Ù‡Ø± batch: {batch_size} ØµÙ†Ø¹Øª)...")
        
        # ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ batch
        for batch_num, i in enumerate(range(0, total_industries, batch_size), 1):
            batch = industry_codes[i:i + batch_size]
            
            logger.info(f"ğŸ“¦ Batch {batch_num}/{(total_industries + batch_size - 1) // batch_size}: "
                       f"Ø¯Ø±ÛŒØ§ÙØª {len(batch)} ØµÙ†Ø¹Øª...")
            
            for code in batch:
                df = self.fetch_industry_data(code)
                
                if df is not None and not df.empty:
                    all_data.append(df)
                else:
                    failed_industries.append(code)
                
                # ØªØ§Ø®ÛŒØ± Ú©ÙˆØªØ§Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ÙØ´Ø§Ø± Ø¨Ù‡ Ø³Ø±ÙˆØ±
                time.sleep(0.3)
            
            # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† batchâ€ŒÙ‡Ø§
            if i + batch_size < total_industries:
                logger.info(f"â¸ï¸  ØªÙˆÙ‚Ù 2 Ø«Ø§Ù†ÛŒÙ‡ Ø¨ÛŒÙ† batchâ€ŒÙ‡Ø§...")
                time.sleep(2)
        
        # Ú¯Ø²Ø§Ø±Ø´ Ù†ØªÛŒØ¬Ù‡
        if failed_industries:
            logger.warning(f"âš ï¸  ØµÙ†Ø§ÛŒØ¹ Ø¨Ø§ Ø®Ø·Ø§ ({len(failed_industries)}): {', '.join(failed_industries)}")
        
        if not all_data:
            logger.error("âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯!")
            return pd.DataFrame()
        
        # Ø§Ø¯ØºØ§Ù… Ù‡Ù…Ù‡ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…â€ŒÙ‡Ø§
        final_df = pd.concat(all_data, ignore_index=True)
        
        logger.info(f"âœ… Ø¬Ù…Ø¹ {len(final_df)} Ø³Ù‡Ù… Ø§Ø² {len(all_data)}/{total_industries} ØµÙ†Ø¹Øª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
        
        return final_df
    
    def get_available_industries(self) -> dict:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ØµÙ†Ø§ÛŒØ¹ Ù…ÙˆØ¬ÙˆØ¯
        
        Returns:
            Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ú©Ø¯Ù‡Ø§ Ùˆ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ ØµÙ†Ø§ÛŒØ¹
        """
        return self.industry_names
    
    def _convert_dtypes(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ØªØ¨Ø¯ÛŒÙ„ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±
        
        Args:
            df: DataFrame ÙˆØ±ÙˆØ¯ÛŒ
            
        Returns:
            DataFrame Ø¨Ø§ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØµØ­ÛŒØ­ Ùˆ ÙˆØ§Ø­Ø¯Ù‡Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯Ù‡
        """
        # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ (integer)
        int_columns = [
            'id', 'volume', 'value', 'first_price', 'high_price', 'low_price',
            'last_price', 'final_price', 'diff_last_final',
            'buy_order_value', 'sell_order_value', 'diff_buy_sell_order',
            'avg_monthly_value', 'avg_3_month_value', 'marketcap'
        ]
        
        # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ (float)
        float_columns = [
            'first_price_change_percent', 'high_price_change_percent',
            'low_price_change_percent', 'last_price_change_percent',
            'final_price_change_percent', 'volatility',
            'sarane_kharid', 'sarane_forosh', 'godrat_kharid', 'pol_hagigi',
            'avg_5_day_pol_hagigi', 'avg_20_day_pol_hagigi', 'avg_60_day_pol_hagigi',
            '5_day_pol_hagigi', '20_day_pol_hagigi', '60_day_pol_hagigi',
            '5_day_godrat_kharid', '20_day_godrat_kharid',
            'value_to_avg_monthly_value', 'value_to_avg_3_month_value',
            '5_day_return', '20_day_return', '60_day_return', 'value_to_marketcap'
        ]
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ int
        for col in int_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('int64')
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ float
        for col in float_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0).astype('float64')
        
        # symbol Ø¨Ø§ÛŒØ¯ string Ø¨Ù…ÙˆÙ†Ù‡
        if 'symbol' in df.columns:
            df['symbol'] = df['symbol'].astype(str)
        
        # ========================================
        # ØªØ¨Ø¯ÛŒÙ„ ÙˆØ§Ø­Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø±Ø§Ø­Øªâ€ŒØªØ±
        # ========================================
        
        # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¨Ø²Ø±Ú¯: ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± 10 Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ (Ø¨Ù‡ Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†)
        billion_columns = [
            'pol_hagigi', 'value', 'marketcap',
            'buy_order_value', 'sell_order_value', 'diff_buy_sell_order',
            'avg_5_day_pol_hagigi', 'avg_20_day_pol_hagigi', 'avg_60_day_pol_hagigi',
            '5_day_pol_hagigi', '20_day_pol_hagigi', '60_day_pol_hagigi',
            'avg_monthly_value', 'avg_3_month_value'
        ]
        
        for col in billion_columns:
            if col in df.columns:
                df[col] = df[col] / 10_000_000_000  # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†
        
        # Ø³Ø±Ø§Ù†Ù‡ Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´: ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± 10 Ù…ÛŒÙ„ÛŒÙˆÙ† (Ø¨Ù‡ Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†)
        million_columns = [
            'sarane_kharid', 'sarane_forosh'
        ]
        
        for col in million_columns:
            if col in df.columns:
                df[col] = df[col] / 10_000_000  # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†
        
        # ========================================
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
        # ========================================
        
        # Ù†Ø³Ø¨Øª ÙˆØ±ÙˆØ¯ Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø±Ø²Ø´ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø§Ù‡Ø§Ù†Ù‡
        if 'pol_hagigi' in df.columns and 'avg_monthly_value' in df.columns:
            df['pol_hagigi_to_avg_monthly_value'] = df.apply(
                lambda row: row['pol_hagigi'] / row['avg_monthly_value'] 
                if row['avg_monthly_value'] != 0 else 0, 
                axis=1
            )
        
        return df