"""
Ù…Ø¯ÛŒØ±ÛŒØª Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ Ø¨Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± GitHub Gist
Ù†Ø³Ø®Ù‡ Async Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÙˆØ§Ø²ÛŒ
"""
import json
import aiohttp
import asyncio
import requests  # ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø§ÙˆÙ„ÛŒÙ‡ Gist
from datetime import datetime
import jdatetime
import logging
from typing import Optional
import time

logger = logging.getLogger(__name__)


class GistAlertManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ Ø¨Ø§ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ø± GitHub Gist - Ù†Ø³Ø®Ù‡ Async"""

    def __init__(self, github_token: str, gist_id: str = None):
        self.github_token = github_token
        self.gist_id = gist_id
        self.api_url = "https://api.github.com/gists"
        self.headers = {
            "Authorization": f"token {github_token}",
            "Accept": "application/vnd.github.v3+json"
        }
        self.today_jalali = jdatetime.date.today().strftime("%Y-%m-%d")

        # Lock Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² race condition
        self._lock = asyncio.Lock()

        # Cache Ù…Ø­Ù„ÛŒ
        self._cache = None
        self._cache_time = 0
        self._cache_duration = 10  # Ø«Ø§Ù†ÛŒÙ‡

        if not self.gist_id:
            # Ø§ÛŒØ¬Ø§Ø¯ Gist Ø¨Ø§ÛŒØ¯ sync Ø¨Ø§Ø´Ù‡ (ÙÙ‚Ø· ÛŒÚ©Ø¨Ø§Ø± Ø§ÙˆÙ„)
            self._create_new_gist_sync()

    def _create_new_gist_sync(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Gist Ø¬Ø¯ÛŒØ¯ - sync (ÙÙ‚Ø· Ø¯Ø± init)"""
        initial_data = {self.today_jalali: []}
        payload = {
            "description": "Bourse Tracker Alert Cache - Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ Ø¨ÙˆØ±Ø³",
            "public": False,
            "files": {
                "alert_cache.json": {"content": json.dumps(initial_data, ensure_ascii=False, indent=2)},
                "README.md": {"content": "# Bourse Alert Cache\nØ§ÛŒÙ† Gist Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯."}
            }
        }
        try:
            response = requests.post(self.api_url, headers=self.headers, json=payload, timeout=10)
            if response.status_code == 201:
                gist_data = response.json()
                self.gist_id = gist_data["id"]
                logger.info(f"âœ… Gist Ø¬Ø¯ÛŒØ¯ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {self.gist_id}")
            else:
                raise Exception(f"Failed to create Gist: {response.text}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Gist: {e}")
            raise

    async def _load_gist_content(self, use_cache: bool = True) -> dict:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Gist Ø¨Ø§ aiohttp"""
        if not self.gist_id:
            return {}

        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² cache Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª
        current_time = time.time()
        if use_cache and self._cache is not None and (current_time - self._cache_time) < self._cache_duration:
            return self._cache.copy()

        try:
            url = f"{self.api_url}/{self.gist_id}"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=self.headers, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    if response.status == 200:
                        gist_data = await response.json()
                        content = gist_data["files"].get("alert_cache.json", {}).get("content", "{}")
                        data = json.loads(content)

                        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ cache
                        self._cache = data
                        self._cache_time = current_time

                        return data
                    else:
                        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Gist: {response.status}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Gist: {e}")
        return {}

    async def _save_to_gist(self, data: dict, max_retries: int = 3) -> bool:
        """
        Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Gist Ø¨Ø§ aiohttp Ùˆ retry mechanism
        
        Args:
            data: Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆØ¯
            max_retries: ØªØ¹Ø¯Ø§Ø¯ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
        
        Returns:
            True Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØª
        """
        if not self.gist_id:
            logger.error("âŒ Gist ID Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª")
            return False

        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Lock Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨ÙˆØ¯Ù† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
        async with self._lock:
            for attempt in range(max_retries):
                try:
                    # Ø¯Ø± ØµÙˆØ±Øª ConflictØŒ Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†ÛŒÙ…
                    if attempt > 0:
                        logger.warning(f"ğŸ”„ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ {attempt}/{max_retries}...")
                        await asyncio.sleep(0.5 * attempt)
                        # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ù†Ø³Ø®Ù‡ Gist
                        current_data = await self._load_gist_content(use_cache=False)
                        # Ø§Ø¯ØºØ§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                        if self.today_jalali in current_data and self.today_jalali in data:
                            # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² duplicate
                            existing_alerts = {
                                (a["symbol"], a["alert_type"]) 
                                for a in current_data[self.today_jalali]
                            }
                            new_alerts = [
                                a for a in data[self.today_jalali]
                                if (a["symbol"], a["alert_type"]) not in existing_alerts
                            ]
                            current_data[self.today_jalali].extend(new_alerts)
                            data = current_data
                        else:
                            data.update(current_data)

                    # Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ÙÙ‚Ø· Û³ Ø±ÙˆØ² Ø§Ø®ÛŒØ±
                    sorted_days = sorted(data.keys(), reverse=True)[:3]
                    new_data = {day: data[day] for day in sorted_days}

                    payload = {
                        "files": {
                            "alert_cache.json": {
                                "content": json.dumps(new_data, ensure_ascii=False, indent=2)
                            }
                        }
                    }

                    url = f"{self.api_url}/{self.gist_id}"
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.patch(
                            url, 
                            headers=self.headers, 
                            json=payload, 
                            timeout=aiohttp.ClientTimeout(total=10)
                        ) as response:
                            if response.status == 200:
                                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ cache
                                self._cache = new_data
                                self._cache_time = time.time()

                                if attempt > 0:
                                    logger.info(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙÙ‚ Ø¯Ø± ØªÙ„Ø§Ø´ {attempt + 1}")
                                return True
                            elif response.status == 409:
                                # Conflict - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ù‡ ØªÙ„Ø§Ø´ Ø¨Ø¹Ø¯ÛŒ
                                logger.warning(f"âš ï¸ Conflict (409) Ø¯Ø± ØªÙ„Ø§Ø´ {attempt + 1}/{max_retries}")
                                continue
                            else:
                                logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Gist: {response.status}")
                                return False

                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Gist (ØªÙ„Ø§Ø´ {attempt + 1}): {e}")
                    if attempt == max_retries - 1:
                        return False

            logger.error(f"âŒ Ø°Ø®ÛŒØ±Ù‡ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨Ø¹Ø¯ Ø§Ø² {max_retries} ØªÙ„Ø§Ø´")
            return False

    def should_send_alert(self, symbol: str, alert_type: str) -> bool:
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø¨Ø§ÛŒØ¯ Ù‡Ø´Ø¯Ø§Ø± Ø§Ø±Ø³Ø§Ù„ Ø´ÙˆØ¯ ÛŒØ§ Ù†Ù‡
        Ø§ÛŒÙ† Ù…ØªØ¯ sync Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯ Ú†ÙˆÙ† ÙÙ‚Ø· cache Ù…Ø­Ù„ÛŒ Ø±Ùˆ Ú†Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù‡
        """
        if self._cache is None:
            # Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± - Ø¨Ø§ÛŒØ¯ sync load Ú©Ù†ÛŒÙ…
            try:
                url = f"{self.api_url}/{self.gist_id}"
                response = requests.get(url, headers=self.headers, timeout=5)
                if response.status_code == 200:
                    gist_data = response.json()
                    content = gist_data["files"].get("alert_cache.json", {}).get("content", "{}")
                    self._cache = json.loads(content)
                    self._cache_time = time.time()
                else:
                    logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± load Ø§ÙˆÙ„ÛŒÙ‡ Gist: status {response.status_code}")
                    self._cache = {}
            except Exception as e:
                logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± load Ø§ÙˆÙ„ÛŒÙ‡ Gist: {e}")
                self._cache = {}
        
        today_alerts = self._cache.get(self.today_jalali, [])
        for alert in today_alerts:
            if alert["symbol"] == symbol and alert["alert_type"] == alert_type:
                return False
        return True

    async def mark_multiple_as_sent(self, alerts: list) -> bool:
        """
        Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ú†Ù†Ø¯ÛŒÙ† Ù‡Ø´Ø¯Ø§Ø± Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ©Ø¬Ø§ - Ù†Ø³Ø®Ù‡ async
        
        Args:
            alerts: Ù„ÛŒØ³ØªÛŒ Ø§Ø² tuple Ù‡Ø§ÛŒ (symbol, alert_type)
        
        Returns:
            True Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØª
        """
        if not alerts:
            return True

        data = await self._load_gist_content(use_cache=False)

        if self.today_jalali not in data:
            data[self.today_jalali] = []

        # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² duplicate
        existing_alerts = {(a["symbol"], a["alert_type"]) for a in data[self.today_jalali]}

        new_alerts = [
            {"symbol": symbol, "alert_type": alert_type}
            for symbol, alert_type in alerts
            if (symbol, alert_type) not in existing_alerts
        ]

        if new_alerts:
            data[self.today_jalali].extend(new_alerts)
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ cache Ù…Ø­Ù„ÛŒ
            self._cache = data
            self._cache_time = time.time()
            # Ø°Ø®ÛŒØ±Ù‡ async
            return await self._save_to_gist(data)

        return True

    async def get_today_stats(self) -> dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø§Ù…Ø±ÙˆØ² - Ù†Ø³Ø®Ù‡ async"""
        data = await self._load_gist_content()
        today_alerts = data.get(self.today_jalali, [])
        alert_counts = {}
        for alert in today_alerts:
            alert_type = alert["alert_type"]
            alert_counts[alert_type] = alert_counts.get(alert_type, 0) + 1
        return {
            "date": self.today_jalali,
            "total_alerts": len(today_alerts),
            "alerts_by_type": alert_counts,
            "gist_id": self.gist_id
        }

    def get_gist_url(self) -> Optional[str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø¯Ø±Ø³ Gist"""
        if self.gist_id:
            return f"https://gist.github.com/{self.gist_id}"
        return None